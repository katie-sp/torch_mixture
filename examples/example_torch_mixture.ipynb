{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e07516-18d0-405e-a6d5-5837d2b06a8e",
   "metadata": {},
   "source": [
    "# Example notebook for torch_mixture package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3fd86c3-8ec0-40ed-8f14-de97d5030c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_mixture import torch_mixture\n",
    "import torch.distributions as tdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3efe57f3-8f84-4927-9178-6acafb33a815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.distributions.normal.Normal,\n",
       " torch.distributions.log_normal.LogNormal,\n",
       " torch.distributions.gamma.Gamma,\n",
       " torch.distributions.gumbel.Gumbel,\n",
       " torch.distributions.cauchy.Cauchy,\n",
       " torch.distributions.studentT.StudentT,\n",
       " torch.distributions.laplace.Laplace,\n",
       " torch.distributions.beta.Beta,\n",
       " torch.distributions.exponential.Exponential,\n",
       " torch.distributions.fishersnedecor.FisherSnedecor,\n",
       " torch.distributions.half_cauchy.HalfCauchy,\n",
       " torch.distributions.half_normal.HalfNormal,\n",
       " torch.distributions.pareto.Pareto,\n",
       " torch.distributions.poisson.Poisson,\n",
       " torch.distributions.bernoulli.Bernoulli,\n",
       " torch.distributions.uniform.Uniform]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch_mixture supports most of the univariate torch distributions\n",
    "torch_mixture.available_distributions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c962403-ee31-47b5-bd71-aaf58e471f07",
   "metadata": {},
   "source": [
    "## Example: fitting two log normal models to FOSL2 fragment length data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a88a6e-439d-4143-8eeb-216d82398ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11c36d88-4184-49cb-9759-dffebca673c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fosl2 = pd.read_csv('/home/katie/torch_mixture/examples/FOSL2_frag_lengths.txt',\n",
    "                   header=None).values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d0bfb0-2299-4c9f-bfd5-4dcd807e05b7",
   "metadata": {},
   "source": [
    "### Fitting the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22d291f5-c0c2-4c88-b24a-b22610110e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-17 23:21:52.588723\n",
      "at initialization negative log-likelihood is 149,468,816.0\n",
      "negative log-likelihood is 141,743,360.0\n",
      "relative gradients are [0.00695877 0.00804878 0.01465199 0.00069342]\n",
      "weights: [0.38 0.62]\n",
      "2021-10-17 23:22:10.009233\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "\n",
    "# Mixture object requires a 1D numpy array and a list of torch distributions\n",
    "# Optionally (recommended): you can initialize with k means clustering rather than random initialization\n",
    "mix = torch_mixture.Mixture(fosl2, [tdist.LogNormal, tdist.LogNormal], cluster_initialize=True)\n",
    "\n",
    "# fit takes two parameters:\n",
    "# learning_rate: learning rate used by Adam optimizer, e.g. 1e-1\n",
    "# n_iter: number of iterations to run the optimizer, e.g. 500\n",
    "mix.fit(1e-1, 500)\n",
    "\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f8a111-2858-41f0-ad8c-2e331757b4cf",
   "metadata": {},
   "source": [
    "### Using the mixture models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad3c6d99-c6fd-492c-894f-a882648d3d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: LogNormal()\n",
      "Weight: 0.3831370770931244\n",
      "Mean: 297.19354248046875\n",
      "Standard deviation: 171.36109924316406\n",
      "\n",
      "Model 2: LogNormal()\n",
      "Weight: 0.6166378259658813\n",
      "Mean: 151.3415069580078\n",
      "Standard deviation: 115.76274108886719\n"
     ]
    }
   ],
   "source": [
    "# get fitted models, weights, and parameters\n",
    "dists = mix.calc_distributions()\n",
    "weights = mix.weights.cpu()\n",
    "\n",
    "print(\"Model 1: {}\\nWeight: {}\\nMean: {}\\nStandard deviation: {}\\n\\n\\\n",
    "Model 2: {}\\nWeight: {}\\nMean: {}\\nStandard deviation: {}\" \\\n",
    "      .format(str(dists[0]), mix.weights[0], dists[0].mean, dists[0].stddev,\n",
    "              str(dists[1]), mix.weights[1], dists[1].mean, dists[1].stddev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e163907c-d23b-4abb-9cba-0b5a3f70570d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6523, 0.3482],\n",
       "        [0.6977, 0.3024],\n",
       "        [0.8063, 0.1939]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# predict some example observations\n",
    "mix.predict(torch.tensor([300, 350, 1000]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
